{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import string\n",
    "from langdetect import detect\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "#pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing all our tweets for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in all tweets from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_1 = pd.read_csv(\"../data/jan_march_2020.csv\")\n",
    "tweets_2 = pd.read_csv(\"../data/april_june_10_2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.concat([tweets_1, tweets_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframes together\n",
    "df = pd.concat([tweets_1, tweets_2], sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-30 21:48:34+00:00</td>\n",
       "      <td>Now available! New guidelines to help countries maintain essential health services &amp;amp; safeguard health care workers during #COVID19 outbreak. http://bit.ly/3aq6CRg #coronavirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-30 15:18:36+00:00</td>\n",
       "      <td>The full briefing on #COVID19 by @DrTedros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-30 15:06:33+00:00</td>\n",
       "      <td>\"In the eye of a storm like #COVID19, scientific and public health tools are essential, but so are humility and kindness. With solidarity, humility and assuming the best of each other, we can – and will – overcome this together\"-@DrTedros #coronavirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-30 15:06:07+00:00</td>\n",
       "      <td>\"Yesterday I sent a tweet with a single word: humility. Some people asked me why. #COVID19 is reminding us how vulnerable we are, how connected we are and how dependent we are on each other\"-@DrTedros #coronavirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-30 15:05:08+00:00</td>\n",
       "      <td>\"We continue to be encouraged by the signs of global solidarity to confront &amp; overcome this common threat. The commitment of @g20org countries to work together to improve the production &amp;amp; equitable supply of essential products shows that the world is coming together\"-@DrTedros</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0  \\\n",
       "0  2020-03-30 21:48:34+00:00   \n",
       "1  2020-03-30 15:18:36+00:00   \n",
       "2  2020-03-30 15:06:33+00:00   \n",
       "3  2020-03-30 15:06:07+00:00   \n",
       "4  2020-03-30 15:05:08+00:00   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                           1  \n",
       "0  Now available! New guidelines to help countries maintain essential health services &amp; safeguard health care workers during #COVID19 outbreak. http://bit.ly/3aq6CRg #coronavirus                                                                                                        \n",
       "1  The full briefing on #COVID19 by @DrTedros                                                                                                                                                                                                                                                 \n",
       "2  \"In the eye of a storm like #COVID19, scientific and public health tools are essential, but so are humility and kindness. With solidarity, humility and assuming the best of each other, we can – and will – overcome this together\"-@DrTedros #coronavirus                                \n",
       "3  \"Yesterday I sent a tweet with a single word: humility. Some people asked me why. #COVID19 is reminding us how vulnerable we are, how connected we are and how dependent we are on each other\"-@DrTedros #coronavirus                                                                      \n",
       "4  \"We continue to be encouraged by the signs of global solidarity to confront & overcome this common threat. The commitment of @g20org countries to work together to improve the production &amp; equitable supply of essential products shows that the world is coming together\"-@DrTedros  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"0\":\"date\",\n",
    "          \"1\":\"text\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df['text'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase text\n",
    "df[\"text\"] = df[\"text\"].str.lower()\n",
    "\n",
    "\n",
    "\n",
    "# remove URLs\n",
    "df['text'] = df['text'].map(lambda x: re.sub('http[s]?:\\/\\/[^\\s]*', ' ', x))\n",
    "\n",
    "\n",
    "# remove URL cutoffs\n",
    "df['text'] = df['text'].map(lambda x: re.sub('\\\\[^\\s]*', ' ', x))\n",
    "\n",
    "\n",
    "\n",
    "# remove spaces\n",
    "df['text'] = df['text'].map(lambda x: re.sub('\\n', ' ', x))\n",
    "\n",
    "\n",
    "# remove picture URLs\n",
    "df['text'] = df['text'].map(lambda x: re.sub('pic.twitter.com\\/[^\\s]*', ' ', x))\n",
    "\n",
    "# remove blog/map type\n",
    "df['text'] = df['text'].map(lambda x: re.sub('blog\\/maps\\/info\\/[^\\s]*', ' ', x))\n",
    "\n",
    "\n",
    "\n",
    "# remove hashtags =\n",
    "df[\"text\"] = df[\"text\"].map(lambda x: re.sub(\"\\#[\\w]*\", \"\", x))\n",
    "\n",
    "\n",
    "# remove AT users\n",
    "df[\"text\"] = df[\"text\"].map(lambda x: re.sub(\"\\@[\\w]*\", \"\", x))\n",
    "\n",
    "#df['text'] = df['text'].apply(strip_all_entities)\n",
    "\n",
    "\n",
    "\n",
    "# remove single quotations\n",
    "df[\"text\"] = df[\"text\"].map(lambda x: re.sub(\"'\", \"\", x))\n",
    "df[\"text\"] = df[\"text\"].map(lambda x: re.sub(\"'\", \"\", x))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# remove characters that are not word characters or digits\n",
    "df[\"text\"] = df[\"text\"].map(lambda x: re.sub(\"[^\\w\\d]\", \" \", x))\n",
    "\n",
    "# remove all characters that are not letters\n",
    "df['text'] = df['text'].map(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x))\n",
    "\n",
    "# remove multiple spaces\n",
    "df['text'] = df['text'].map(lambda x: re.sub(\"\\s{2,6}\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4247, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate rows\n",
    "df.drop_duplicates(subset='text', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove multiple spaces\n",
    "df['text'] = df['text'].map(lambda x: re.sub(\"\\s{3,20}\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop row with only one space\n",
    "df = df[~(df[\"text\"]== \" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop row with multiple spaces\n",
    "df = df[~(df[\"text\"]== \"  \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop row with multiple spaces\n",
    "df = df[~(df[\"text\"]== \" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop empty row\n",
    "df = df[~(df[\"text\"]== \"\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect languages of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code was used to test for errors that would prevent the detect function from running\n",
    "# languages = []\n",
    "# for i in range(101,150):\n",
    "#     try:\n",
    "#         languages.append(detect(df.iloc[i, 0]))\n",
    "#     except:\n",
    "#         print(f\"error in row {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply detect function on text column\n",
    "df[\"languages\"] = df[\"text\"].apply(detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63711, 3)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select for tweets that are English only\n",
    "## this dropped 3_335 rows \n",
    "df_en = df[df[\"languages\"] == \"en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60352, 3)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue cleaning on english column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are removing multiple copies of the same letter. For example \"thanksssssssss\" is updated to \"thanks\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:576: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    }
   ],
   "source": [
    "# Wrote this as a function but it took forever to run, so breaking it out individually\n",
    "# Saving code for future reference\n",
    "\n",
    "# # list of all English letters\n",
    "# letters = list(string.ascii_lowercase)\n",
    "\n",
    "# # list of letters that typically don't repeat twice in an English word\n",
    "# double_letters = [\"q\", \"u\", \"w\", \"y\"]\n",
    "\n",
    "# def remove_repeats(letters):\n",
    "#     for letter in letters:\n",
    "#         if letter in double_letters:\n",
    "#             df_en[\"text\"].map(lambda x: re.sub(re.escape(letter)+\"{2,10}\", re.escape(letter), x))\n",
    "#         else:\n",
    "#             df_en[\"text\"].map(lambda x: re.sub(re.escape(letter)+\"{3,10}\", re.escape(letter), x))\n",
    "\n",
    "\n",
    "# df_en.loc[:, \"text\"] = df_en[\"text\"].map(remove_repeats)\n",
    "\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"a{3,10}\", \"a\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"b{3,10}\", \"b\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"c{3,10}\", \"c\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"d{3,10}\", \"d\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"e{3,10}\", \"e\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"f{3,10}\", \"f\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"g{3,10}\", \"g\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"h{3,10}\", \"h\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"i{3,10}\", \"i\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"j{3,10}\", \"j\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"k{3,10}\", \"k\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"l{3,10}\", \"l\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"m{3,10}\", \"m\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"n{3,10}\", \"n\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"o{3,10}\", \"o\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"p{3,10}\", \"p\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"q{2,10}\", \"q\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"r{3,10}\", \"r\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"s{3,10}\", \"s\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"t{3,10}\", \"t\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"u{2,10}\", \"u\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"v{3,10}\", \"v\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"x{3,10}\", \"x\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"y{2,10}\", \"y\", x))\n",
    "df_en.loc[:, \"text\"] = df_en['text'].map(lambda x: re.sub(\"z{3,10}\", \"z\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60352, 3)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csf\n",
    "df_en.to_csv(\"../Data/all_tweets_clean.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
